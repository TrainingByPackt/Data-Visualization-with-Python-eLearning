{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing airbnb data with geoplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last activity for geoplotlib, we will use airbnb listing data to determine the most expensive and best rated regions of accomodations in the New York area.   \n",
    "We will write a custom layer with which we can switch between the price and the review score of each accomodation.   \n",
    "\n",
    "In the end, we will be able to see the hostpots for the most expensive and best rated accomodations across New York.   \n",
    "In theory, we should see a price increase the closer we get to the center of Manhatten. It will be very interesting to see if the ratings for the given accomodations also increase the closer we get to the center of Manhatten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**    \n",
    "If your system is a little bit slower, just use `./data/airbnb_new_york_smaller.csv` which has fewer datapoints. The activity stays the same, we just cut down on the number of datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**   \n",
    "If we import our dataset without defining the `dtypes` specifically - like we did in the chapter about geoplotlib - we will get a warning telling out the it has a mixed datatype.   \n",
    "We can get rid of this warning by explicitly defining the type of the values in this column by using the `dtype` parameter.   \n",
    "We will ignore this since we are only using a small subset of the data in this dataset.   \n",
    "Normally you want to define the `dtypes` of each column of the used dataset to avoid errors later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 rows of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data handling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start plotting our data, we want to *wrangle* our data to fit our needs.   \n",
    "As with all the previous geoplitlib exercises and activites, we have to map the `latitude` and `longitude` columns to `lat` and `lon`.\n",
    "\n",
    "Considering the fact, that there might be some missing data points in the `review_scores_rating` and `price` columns, we want to fill them in with data of the same datatype.   \n",
    "> This is where you would want to apply some data augmentation in real projects.\n",
    "\n",
    "The last step of our pre-processing is to create a sub-section view of our dataset that is much easier to handle and will be used for plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping `Latitude` and `Longitude` to `lat` and `lon`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our dataset has a `latitiude` and a `longitude` column.   \n",
    "As we've already discussed in the lesson about geoplotlib, we need them as `lat` and `lon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping Latitude to lat and Longitude to lon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**   \n",
    "Geoplotlibs methods expect dataset columns `lat` and `lon` for plotting. This means your dataframe has to be tranfsormed to resemble this structure.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping `price` to `dollar_price` as int type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating a color map that changes color based on the price of an accommodation, we need a value that can easily be compared and checked whether it's smaller or bigger than any other listing.   \n",
    "Therefore we will create a new column called `dollar_price` that will hold the value of the `price` column as a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string of type $<numbers> to <nubmers> of type float\n",
    "def convert_to_float(x):\n",
    "    try:\n",
    "        value=str.replace(x[1:], ',', '')\n",
    "        return float(value)\n",
    "    except:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dollar_price column with the price as a number\n",
    "# and replace the NaN values by 0 in the ratings column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing the amount of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 96 columns. When working with such a huge dataset it makes sense to think about what data we really need and create a subsection of our dataset that only holds the data we need.   \n",
    "Before we can do that , we'll take a look at all the columns available and an example for that column. This will help us decide what information is suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the col name and the first entry per column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we want to **only use the fields that help us build the described visualization**.   \n",
    "\n",
    "Those fields are:\n",
    "- **id**\n",
    "- **latitude (as lat)**\n",
    "- **longitude (as lon)**\n",
    "- **price (in $)**\n",
    "- **review_scores_rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subsection of the dataset with the above mentioned columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 rows of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are now left with only 5 of the 96 columns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the spatial features of our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we know that our data holds airbnb listings for New York city, at the moment we have no feeling about the amount, distribution, and character of our dataset.   \n",
    "The simplest way to get a first glance at the data is to plot every listing with a simple dot map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DataAccessObject and create a data object as an instance of that class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the whole dataset with dots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a better understanding about the distribution and character of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the custom layer to map the price and rating to a color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to write the custom layer. Here we want to define a `ValueLayer` that extends the `BaseLayer` of geoplotlib.   \n",
    "For the mentioned interactive feature we need an additional import. `pyglet` provides us with the option to act on key presses.\n",
    "\n",
    "Given the data, we want to plot each point on the map with a color that is defined by the currently selected attribute, either price or rating.   \n",
    "To avoid non-descriptive output, we need to also adjust the scale of our color map. Ratings are between 0 and 100, whereas prices can be much higer. Using a linear (`lin`) scale for the ratings and a logarithmic ('log') scale for the price will give us much better insights into our data.\n",
    "The view (bounding box) of our visualization will be set to New York and a text information with the currently selected attribute will be displayed in the upper right corner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/colorscale.png\" width=500/>   \n",
    "> The jet color map displays low values as cooler tones and higher values as hotter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to assign each point a different color, we simply paint each point separately. This is definitely not the most efficient solution, but it wills suite for now.\n",
    "We will need the following instance variables:   \n",
    "- self.data that holds the dataset\n",
    "- self.display that holds the currently selected attribute name\n",
    "- self.painter holds an instance of the BatchPainter class\n",
    "- self.view holds the BoundingBox\n",
    "- self.cmap holds a color map with the `jet` color schmema, alpha of 255 and 100 levels\n",
    "\n",
    "Inside the `invalidate` method that holds the logic of projection the data to points on the map, we have to switch between the `lin` and `log` scales, depending on the attribute that is currently selected.   \n",
    "The color is then determined by \"placing\" the value between 0/1 and the maximum (`max_val`) value which also has to be taken from the dataset based on what attribute currently is display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom layer creation\n",
    "import pyglet\n",
    "import geoplotlib\n",
    "from geoplotlib.layers import BaseLayer\n",
    "from geoplotlib.core import BatchPainter\n",
    "from geoplotlib.colors import ColorMap\n",
    "from geoplotlib.utils import BoundingBox\n",
    "\n",
    "class ValueLayer(BaseLayer):\n",
    "\n",
    "    def __init__(self, dataset, bbox=BoundingBox.WORLD):\n",
    "        # initialize instance variables\n",
    "        pass\n",
    "        \n",
    "    def invalidate(self, proj):\n",
    "        # paint every point with a color that represents the currently selected attributes value\n",
    "        pass\n",
    "        \n",
    "    def draw(self, proj, mouse_x, mouse_y, ui_manager):\n",
    "        # display the ui manager info\n",
    "        ui_manager.info('Use left and right to switch between the displaying of price and ratings. Currently displaying: {}'.format(self.display))\n",
    "        self.painter.batch_draw()\n",
    "        \n",
    "    def on_key_release(self, key, modifiers):\n",
    "        # check if left or right keys are pressed to switch to other attribute\n",
    "        pass\n",
    "        \n",
    "    # bounding box that gets used when layer is created\n",
    "    def bbox(self):\n",
    "        return self.view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset only contains data from New York, we want to set the view to New York in the beginning.   \n",
    "Therefore we need an instance of the `BoundingBox` class with the given parameters.\n",
    "\n",
    "In addition to a custom `BoundingBox`, we will use the `darkmatter` tile provider we have looked at in lesson 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding box for our view on New York\n",
    "from geoplotlib.utils import BoundingBox\n",
    "\n",
    "ny_bbox = BoundingBox(north=40.897994, west=-73.999040, south=40.595581, east=-73.95040)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying our custom layer using add_layer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
